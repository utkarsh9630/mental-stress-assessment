{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5cbbe87-9489-490d-bb46-d45a7c638b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# ── Stage 1: classify the test_recs.csv split ─────────────────────────────────\n",
    "from predict_classification import load_and_classify\n",
    "import pandas as pd\n",
    "\n",
    "# 1) read the test set you created (with Student_id, Mechanisms, features…)\n",
    "test_recs = pd.read_csv(\"test_recs.csv\")\n",
    "\n",
    "# 2) run your SVM pipeline on that SAME CSV\n",
    "preds = load_and_classify(\"test_recs.csv\")  \n",
    "# preds has columns: pred_int, pred_label, P_low, P_med, P_high\n",
    "\n",
    "# 3) attach Student_id and Mechanisms so you can recommend later\n",
    "test_with_preds = pd.concat([\n",
    "    test_recs[[\"Student_id\",\"Stress Coping Mechanisms\"]].reset_index(drop=True),\n",
    "    preds.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# 4) write out for Stage 2\n",
    "test_with_preds.to_csv(\"predictions.csv\", index=False)\n",
    "print(\"Wrote predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397a1c6e-8be2-4035-871c-f844a6dbc6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification on hold-out ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.63      0.51      0.57       519\n",
      "      Medium       0.67      0.71      0.69       527\n",
      "        High       0.64      0.71      0.67       682\n",
      "\n",
      "    accuracy                           0.65      1728\n",
      "   macro avg       0.65      0.64      0.64      1728\n",
      "weighted avg       0.65      0.65      0.65      1728\n",
      "\n",
      "Confusion matrix:\n",
      " [[265  87 167]\n",
      " [ 53 376  98]\n",
      " [100 101 481]]\n",
      "\n",
      "Average P_category_drop = 0.291\n",
      "\n",
      "Top recommended mechanisms:\n",
      "                  Mechanism  Count\n",
      "0          Watching Sports   1091\n",
      "1               Travelling    941\n",
      "2                     Yoga    919\n",
      "3      Spending Time Alone    880\n",
      "4  Social Media Engagement    874\n",
      "5                 Exercise    872\n",
      "6  Walking or Nature Walks    794\n",
      "7                  Reading    793\n",
      "8               Meditation    746\n",
      "9       Talking to Friends    730\n",
      "\n",
      "=== Recommendation Accuracy on TRAIN ===\n",
      "Accuracy : 0.6324404761904762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.69      0.87      0.77      2821\n",
      "     Success       0.20      0.08      0.11      1211\n",
      "\n",
      "    accuracy                           0.63      4032\n",
      "   macro avg       0.45      0.47      0.44      4032\n",
      "weighted avg       0.54      0.63      0.57      4032\n",
      "\n",
      "\n",
      "=== Recommendation Accuracy on TEST ===\n",
      "Accuracy : 0.6168981481481481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.72      0.75      0.73      1209\n",
      "     Success       0.34      0.31      0.32       519\n",
      "\n",
      "    accuracy                           0.62      1728\n",
      "   macro avg       0.53      0.53      0.53      1728\n",
      "weighted avg       0.60      0.62      0.61      1728\n",
      "\n",
      "Wrote knn_recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# 1) reload train_recs (has features, coping, true category)\n",
    "train = pd.read_csv(\"train_recs.csv\")\n",
    "train[\"Mechanisms\"] = train[\"Stress Coping Mechanisms\"].str.split(\",\")\n",
    "train[\"Success\"]    = (train[\"Stress Level Category\"]==\"Low\").astype(int)\n",
    "\n",
    "# 2) define exactly the features you trained on\n",
    "feature_cols = [\n",
    "  'Age','Academic Performance (GPA)','Study Hours Per Week',\n",
    "  'Social_Media_Usage_per_week','Sleep Duration (Hours per night)',\n",
    "  'Physical Exercise (Hours per week)','Family Support','Financial Stress',\n",
    "  'Peer Pressure','Relationship Stress','Counseling Attendance','Diet Quality',\n",
    "  'Cognitive Distortions','Family Mental Health History','Medical Condition',\n",
    "  'Substance Use','Gender_Female','Gender_Male','Gender_Other','Stress_Ratio'\n",
    "]\n",
    "\n",
    "# 3) fit k-NN on train features\n",
    "X_train = train[feature_cols].values\n",
    "knn = NearestNeighbors(n_neighbors=50, metric=\"euclidean\").fit(X_train)\n",
    "\n",
    "# 4) reload test_recs (with features & coping) and predictions\n",
    "test_recs = pd.read_csv(\"test_recs.csv\")\n",
    "test_recs[\"Mechanisms\"] = test_recs[\"Stress Coping Mechanisms\"].str.split(\",\")\n",
    "\n",
    "preds = pd.read_csv(\"predictions.csv\")[[\n",
    "    \"Student_id\",\"pred_int\",\"pred_label\",\"P_low\",\"P_med\",\"P_high\"\n",
    "]]\n",
    "\n",
    "test = test_recs.merge(preds, on=\"Student_id\", how=\"left\")\n",
    "\n",
    "# 5) recommendation function\n",
    "def recommend_knn(row, knn=knn, train_df=train, feature_cols=feature_cols, k=50, m=5):\n",
    "    x = row[feature_cols].values.reshape(1,-1)\n",
    "    _, idxs = knn.kneighbors(x, n_neighbors=k)\n",
    "    neigh = train_df.iloc[idxs[0]]\n",
    "    stats = {}\n",
    "    for mechs, succ in zip(neigh[\"Mechanisms\"], neigh[\"Success\"]):\n",
    "        for mech in mechs:\n",
    "            stats.setdefault(mech, {\"used\":0,\"succ\":0})\n",
    "            stats[mech][\"used\"] += 1\n",
    "            stats[mech][\"succ\"] += succ\n",
    "    mech_df = pd.DataFrame([\n",
    "        {\"Mechanism\":mech,\n",
    "         \"SuccessRate\":v[\"succ\"]/v[\"used\"]}\n",
    "        for mech,v in stats.items()\n",
    "    ])\n",
    "    already = set(row[\"Mechanisms\"])\n",
    "    mech_df = mech_df[~mech_df[\"Mechanism\"].isin(already)]\n",
    "    return \",\".join(mech_df.sort_values(\"SuccessRate\",ascending=False).head(m)[\"Mechanism\"])\n",
    "\n",
    "# 6) apply recommendations\n",
    "test[\"recommendations\"] = test.apply(recommend_knn, axis=1)\n",
    "\n",
    "# 7) compute P_category_drop\n",
    "def compute_p_drop(row):\n",
    "    if row.pred_int==2: return row.P_med + row.P_low\n",
    "    if row.pred_int==1: return row.P_low\n",
    "    return 0.0\n",
    "\n",
    "test[\"P_category_drop\"] = test.apply(compute_p_drop, axis=1)\n",
    "\n",
    "# ————— A) classification metrics on the hold-out test set —————\n",
    "true = test[\"Stress Level Category\"].map({'Low':0,'Medium':1,'High':2})\n",
    "print(\"=== Classification on hold-out ===\")\n",
    "print(classification_report(true, test[\"pred_int\"], target_names=['Low','Medium','High']))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(true, test[\"pred_int\"]))\n",
    "\n",
    "# ————— B) simple recommendation summaries —————\n",
    "print(f\"\\nAverage P_category_drop = {test['P_category_drop'].mean():.3f}\")\n",
    "rec_df = (\n",
    "    test[\"recommendations\"]\n",
    "      .str.split(\",\")\n",
    "      .explode()\n",
    "      .value_counts()\n",
    "      .rename_axis(\"Mechanism\")\n",
    "      .reset_index(name=\"Count\")\n",
    ")\n",
    "print(\"\\nTop recommended mechanisms:\\n\", rec_df.head(10))\n",
    "\n",
    "# ————— C) recommendation‐model accuracy (train & test) —————\n",
    "thr = 0.5\n",
    "\n",
    "# TRAIN\n",
    "train[\"P_category_drop\"] = None  # placeholder\n",
    "# we need the same P_category_drop on train; recompute via compute_p_drop if you merged preds into train_recs.csv\n",
    "# assume train_recs.csv also had \"pred_int\",\"P_low\",\"P_med\" etc. so:\n",
    "train_preds = pd.read_csv(\"train_predictions.csv\")[[\"Student_id\",\"pred_int\",\"P_low\",\"P_med\",\"P_high\"]]\n",
    "train = train.merge(train_preds, on=\"Student_id\", how=\"left\")\n",
    "train[\"P_category_drop\"] = train.apply(compute_p_drop, axis=1)\n",
    "train[\"PredSuccess\"] = (train[\"P_category_drop\"] > thr).astype(int)\n",
    "\n",
    "print(\"\\n=== Recommendation Accuracy on TRAIN ===\")\n",
    "print(\"Accuracy :\", accuracy_score(train[\"Success\"], train[\"PredSuccess\"]))\n",
    "print(classification_report(train[\"Success\"], train[\"PredSuccess\"], target_names=[\"Fail\",\"Success\"]))\n",
    "\n",
    "# TEST\n",
    "test[\"TrueSuccess\"] = (test[\"Stress Level Category\"]==\"Low\").astype(int)\n",
    "test[\"PredSuccess\"] = (test[\"P_category_drop\"] > thr).astype(int)\n",
    "\n",
    "print(\"\\n=== Recommendation Accuracy on TEST ===\")\n",
    "print(\"Accuracy :\", accuracy_score(test[\"TrueSuccess\"], test[\"PredSuccess\"]))\n",
    "print(classification_report(test[\"TrueSuccess\"], test[\"PredSuccess\"], target_names=[\"Fail\",\"Success\"]))\n",
    "\n",
    "# 8) save final\n",
    "out_cols = [\n",
    "  \"Student_id\",\"pred_label\",\"P_low\",\"P_med\",\"P_high\",\"P_category_drop\",\n",
    "  \"Stress Coping Mechanisms\",\"recommendations\"\n",
    "]\n",
    "test[out_cols].to_csv(\"knn_recommendations.csv\", index=False)\n",
    "print(\"Wrote knn_recommendations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148bf6f5-0316-4aa9-9ad2-74a2dedb402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved knn_model.joblib and rec_feature_columns.json\n"
     ]
    }
   ],
   "source": [
    "import joblib, json\n",
    "\n",
    "# 1. persist the fitted KNN\n",
    "joblib.dump(knn, \"knn_model.joblib\")\n",
    "\n",
    "# 2. persist the feature columns list\n",
    "with open(\"rec_feature_columns.json\",\"w\") as f:\n",
    "    json.dump(feature_cols, f)\n",
    "\n",
    "print(\"Saved knn_model.joblib and rec_feature_columns.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
